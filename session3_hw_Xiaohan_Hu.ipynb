{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOs2iqVSpYqhL2j0kXTbPaz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hxh00138/ai-science-training-series/blob/main/session3_hw_Xiaohan_Hu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJzRaLBRAHM9"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(numpy.float32)\n",
        "x_test  = x_test.astype(numpy.float32)\n",
        "\n",
        "x_train /= 255.\n",
        "x_test  /= 255.\n",
        "\n",
        "y_train = y_train.astype(numpy.int32)\n",
        "y_test  = y_test.astype(numpy.int32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmK8G-w5AQ6r",
        "outputId": "5ed5b5a1-1dc1-42f6-fef8-808872fb6e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10Classifier(tf.keras.models.Model):\n",
        "\n",
        "    def __init__(self, activation=tf.nn.tanh):\n",
        "        tf.keras.models.Model.__init__(self)\n",
        "\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(32, [3, 3], activation='relu')\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu')\n",
        "        self.pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.drop_4 = tf.keras.layers.Dropout(0.25)\n",
        "        self.conv_5 = tf.keras.layers.Conv2D(128, [3, 3], activation='relu')\n",
        "        self.pool_6 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.dense_7 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.drop_8 = tf.keras.layers.Dropout(0.5)\n",
        "        self.dense_9 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.pool_3(x)\n",
        "        x = self.drop_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.pool_6(x)\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        x = self.dense_7(x)\n",
        "        x = self.drop_8(x)\n",
        "        x = self.dense_9(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "3vbAzAnKAVSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network_concise(_batch_size, _n_training_epochs, _lr):\n",
        "\n",
        "    cnn_model = CIFAR10Classifier()\n",
        "\n",
        "    cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "    \n",
        "    history = cnn_model.fit(x_train, y_train, batch_size=_batch_size, epochs=_n_training_epochs)\n",
        "    return history, cnn_model"
      ],
      "metadata": {
        "id": "_YvDq964AaO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This took 43 seconds per epoch on my laptop\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "lr = .01\n",
        "history, cnn_model = train_network_concise(batch_size, epochs, lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q7cOx7zAcAH",
        "outputId": "d3cf15cb-0d9c-41b2-a034-708cb32bd8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 263s 335ms/step - loss: 1.6956 - accuracy: 0.3785\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 260s 332ms/step - loss: 1.3205 - accuracy: 0.5265\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 258s 330ms/step - loss: 1.1604 - accuracy: 0.5889\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 254s 324ms/step - loss: 1.0470 - accuracy: 0.6333\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 253s 324ms/step - loss: 0.9618 - accuracy: 0.6615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#By adding one more convolutional layer and pooling layer and also increasing the epochs, we can increase the accuracy from 50% to 66%."
      ],
      "metadata": {
        "id": "nea5O83aKBAY"
      }
    }
  ]
}